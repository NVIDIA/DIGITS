Log file created at: 2016/12/09 11:25:51
Running on machine: g008
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1209 11:25:51.802104 14757 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112551-7336/solver.prototxt
I1209 11:25:51.803354 14757 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W1209 11:25:51.803365 14757 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I1209 11:25:51.804147 14757 caffe.cpp:217] Using GPUs 0
I1209 11:25:51.846781 14757 caffe.cpp:222] GPU 0: Tesla K20m
I1209 11:25:52.224033 14757 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2
test_interval: 10
base_lr: 0.01
display: 1
max_iter: 40
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 14
snapshot: 20
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 3405691582
net: "train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
type: "SGD"
I1209 11:25:52.225519 14757 solver.cpp:91] Creating training net from net file: train_val.prototxt
I1209 11:25:52.226636 14757 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1209 11:25:52.226652 14757 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I1209 11:25:52.226675 14757 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto"
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_images"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_labels"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "scale"
  type: "Power"
  bottom: "data"
  top: "scale"
  power_param {
    scale: 0.004
  }
}
layer {
  name: "hidden"
  type: "InnerProduct"
  bottom: "scale"
  top: "output"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "output"
  bottom: "label"
  top: "loss"
}
I1209 11:25:52.226899 14757 layer_factory.hpp:77] Creating layer data
I1209 11:25:52.227073 14757 net.cpp:100] Creating Layer data
I1209 11:25:52.227118 14757 net.cpp:408] data -> data
I1209 11:25:52.227180 14757 data_transformer.cpp:25] Loading mean file from: /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto
I1209 11:25:52.229935 14762 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_images
I1209 11:25:52.245885 14757 data_layer.cpp:41] output data size: 10,1,10,10
I1209 11:25:52.247138 14757 net.cpp:150] Setting up data
I1209 11:25:52.247159 14757 net.cpp:157] Top shape: 10 1 10 10 (1000)
I1209 11:25:52.247203 14757 net.cpp:165] Memory required for data: 4000
I1209 11:25:52.247232 14757 layer_factory.hpp:77] Creating layer label
I1209 11:25:52.247334 14757 net.cpp:100] Creating Layer label
I1209 11:25:52.247350 14757 net.cpp:408] label -> label
I1209 11:25:52.251267 14764 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_labels
I1209 11:25:52.251420 14757 data_layer.cpp:41] output data size: 10,1,1,2
I1209 11:25:52.251616 14757 net.cpp:150] Setting up label
I1209 11:25:52.251631 14757 net.cpp:157] Top shape: 10 1 1 2 (20)
I1209 11:25:52.251641 14757 net.cpp:165] Memory required for data: 4080
I1209 11:25:52.251648 14757 layer_factory.hpp:77] Creating layer scale
I1209 11:25:52.251664 14757 net.cpp:100] Creating Layer scale
I1209 11:25:52.251672 14757 net.cpp:434] scale <- data
I1209 11:25:52.251696 14757 net.cpp:408] scale -> scale
I1209 11:25:52.251770 14757 net.cpp:150] Setting up scale
I1209 11:25:52.251781 14757 net.cpp:157] Top shape: 10 1 10 10 (1000)
I1209 11:25:52.251791 14757 net.cpp:165] Memory required for data: 8080
I1209 11:25:52.251796 14757 layer_factory.hpp:77] Creating layer hidden
I1209 11:25:52.251811 14757 net.cpp:100] Creating Layer hidden
I1209 11:25:52.251816 14757 net.cpp:434] hidden <- scale
I1209 11:25:52.251828 14757 net.cpp:408] hidden -> output
I1209 11:25:52.252008 14757 net.cpp:150] Setting up hidden
I1209 11:25:52.252019 14757 net.cpp:157] Top shape: 10 2 (20)
I1209 11:25:52.252034 14757 net.cpp:165] Memory required for data: 8160
I1209 11:25:52.252064 14757 layer_factory.hpp:77] Creating layer loss
I1209 11:25:52.252079 14757 net.cpp:100] Creating Layer loss
I1209 11:25:52.252087 14757 net.cpp:434] loss <- output
I1209 11:25:52.252094 14757 net.cpp:434] loss <- label
I1209 11:25:52.252104 14757 net.cpp:408] loss -> loss
I1209 11:25:52.252168 14757 net.cpp:150] Setting up loss
I1209 11:25:52.252179 14757 net.cpp:157] Top shape: (1)
I1209 11:25:52.252187 14757 net.cpp:160]     with loss weight 1
I1209 11:25:52.252220 14757 net.cpp:165] Memory required for data: 8164
I1209 11:25:52.252228 14757 net.cpp:226] loss needs backward computation.
I1209 11:25:52.252243 14757 net.cpp:226] hidden needs backward computation.
I1209 11:25:52.252249 14757 net.cpp:228] scale does not need backward computation.
I1209 11:25:52.252254 14757 net.cpp:228] label does not need backward computation.
I1209 11:25:52.252259 14757 net.cpp:228] data does not need backward computation.
I1209 11:25:52.252264 14757 net.cpp:270] This network produces output loss
I1209 11:25:52.252276 14757 net.cpp:283] Network initialization done.
I1209 11:25:52.252854 14757 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I1209 11:25:52.252892 14757 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1209 11:25:52.252899 14757 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I1209 11:25:52.252912 14757 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto"
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_images"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_labels"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "scale"
  type: "Power"
  bottom: "data"
  top: "scale"
  power_param {
    scale: 0.004
  }
}
layer {
  name: "hidden"
  type: "InnerProduct"
  bottom: "scale"
  top: "output"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "output"
  bottom: "label"
  top: "loss"
}
I1209 11:25:52.253049 14757 layer_factory.hpp:77] Creating layer data
I1209 11:25:52.253140 14757 net.cpp:100] Creating Layer data
I1209 11:25:52.253162 14757 net.cpp:408] data -> data
I1209 11:25:52.253178 14757 data_transformer.cpp:25] Loading mean file from: /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto
I1209 11:25:52.255550 14766 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_images
I1209 11:25:52.255774 14757 data_layer.cpp:41] output data size: 10,1,10,10
I1209 11:25:52.256006 14757 net.cpp:150] Setting up data
I1209 11:25:52.256021 14757 net.cpp:157] Top shape: 10 1 10 10 (1000)
I1209 11:25:52.256031 14757 net.cpp:165] Memory required for data: 4000
I1209 11:25:52.256039 14757 layer_factory.hpp:77] Creating layer label
I1209 11:25:52.256116 14757 net.cpp:100] Creating Layer label
I1209 11:25:52.256131 14757 net.cpp:408] label -> label
I1209 11:25:52.258656 14768 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_labels
I1209 11:25:52.258854 14757 data_layer.cpp:41] output data size: 10,1,1,2
I1209 11:25:52.259062 14757 net.cpp:150] Setting up label
I1209 11:25:52.259076 14757 net.cpp:157] Top shape: 10 1 1 2 (20)
I1209 11:25:52.259086 14757 net.cpp:165] Memory required for data: 4080
I1209 11:25:52.259095 14757 layer_factory.hpp:77] Creating layer scale
I1209 11:25:52.259111 14757 net.cpp:100] Creating Layer scale
I1209 11:25:52.259122 14757 net.cpp:434] scale <- data
I1209 11:25:52.259132 14757 net.cpp:408] scale -> scale
I1209 11:25:52.259228 14757 net.cpp:150] Setting up scale
I1209 11:25:52.259241 14757 net.cpp:157] Top shape: 10 1 10 10 (1000)
I1209 11:25:52.259250 14757 net.cpp:165] Memory required for data: 8080
I1209 11:25:52.259256 14757 layer_factory.hpp:77] Creating layer hidden
I1209 11:25:52.259266 14757 net.cpp:100] Creating Layer hidden
I1209 11:25:52.259272 14757 net.cpp:434] hidden <- scale
I1209 11:25:52.259284 14757 net.cpp:408] hidden -> output
I1209 11:25:52.259414 14757 net.cpp:150] Setting up hidden
I1209 11:25:52.259425 14757 net.cpp:157] Top shape: 10 2 (20)
I1209 11:25:52.259433 14757 net.cpp:165] Memory required for data: 8160
I1209 11:25:52.259450 14757 layer_factory.hpp:77] Creating layer loss
I1209 11:25:52.259461 14757 net.cpp:100] Creating Layer loss
I1209 11:25:52.259466 14757 net.cpp:434] loss <- output
I1209 11:25:52.259474 14757 net.cpp:434] loss <- label
I1209 11:25:52.259485 14757 net.cpp:408] loss -> loss
I1209 11:25:52.259534 14757 net.cpp:150] Setting up loss
I1209 11:25:52.259544 14757 net.cpp:157] Top shape: (1)
I1209 11:25:52.259557 14757 net.cpp:160]     with loss weight 1
I1209 11:25:52.259567 14757 net.cpp:165] Memory required for data: 8164
I1209 11:25:52.259572 14757 net.cpp:226] loss needs backward computation.
I1209 11:25:52.259578 14757 net.cpp:226] hidden needs backward computation.
I1209 11:25:52.259584 14757 net.cpp:228] scale does not need backward computation.
I1209 11:25:52.259589 14757 net.cpp:228] label does not need backward computation.
I1209 11:25:52.259594 14757 net.cpp:228] data does not need backward computation.
I1209 11:25:52.259599 14757 net.cpp:270] This network produces output loss
I1209 11:25:52.259608 14757 net.cpp:283] Network initialization done.
I1209 11:25:52.259644 14757 solver.cpp:60] Solver scaffolding done.
I1209 11:25:52.259755 14757 caffe.cpp:251] Starting Optimization
I1209 11:25:52.259768 14757 solver.cpp:279] Solving 
I1209 11:25:52.259773 14757 solver.cpp:280] Learning Rate Policy: step
I1209 11:25:52.259891 14757 solver.cpp:337] Iteration 0, Testing net (#0)
I1209 11:25:52.260046 14757 blocking_queue.cpp:50] Data layer prefetch queue empty
I1209 11:25:52.261816 14757 solver.cpp:404]     Test net output #0: loss = 0.0933352 (* 1 = 0.0933352 loss)
I1209 11:25:52.262502 14757 solver.cpp:228] Iteration 0, loss = 0.0855033
I1209 11:25:52.262528 14757 solver.cpp:244]     Train net output #0: loss = 0.0855033 (* 1 = 0.0855033 loss)
I1209 11:25:52.262554 14757 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1209 11:25:52.263037 14757 solver.cpp:228] Iteration 1, loss = 0.0785537
I1209 11:25:52.263058 14757 solver.cpp:244]     Train net output #0: loss = 0.0785537 (* 1 = 0.0785537 loss)
I1209 11:25:52.263069 14757 sgd_solver.cpp:106] Iteration 1, lr = 0.01
I1209 11:25:52.263506 14757 solver.cpp:228] Iteration 2, loss = 0.0945713
I1209 11:25:52.263527 14757 solver.cpp:244]     Train net output #0: loss = 0.0945713 (* 1 = 0.0945713 loss)
I1209 11:25:52.263537 14757 sgd_solver.cpp:106] Iteration 2, lr = 0.01
I1209 11:25:52.263967 14757 solver.cpp:228] Iteration 3, loss = 0.0646118
I1209 11:25:52.263988 14757 solver.cpp:244]     Train net output #0: loss = 0.0646118 (* 1 = 0.0646118 loss)
I1209 11:25:52.263998 14757 sgd_solver.cpp:106] Iteration 3, lr = 0.01
I1209 11:25:52.264426 14757 solver.cpp:228] Iteration 4, loss = 0.0857749
I1209 11:25:52.264447 14757 solver.cpp:244]     Train net output #0: loss = 0.0857749 (* 1 = 0.0857749 loss)
I1209 11:25:52.264456 14757 sgd_solver.cpp:106] Iteration 4, lr = 0.01
I1209 11:25:52.264868 14757 solver.cpp:228] Iteration 5, loss = 0.0755682
I1209 11:25:52.264889 14757 solver.cpp:244]     Train net output #0: loss = 0.0755682 (* 1 = 0.0755682 loss)
I1209 11:25:52.264899 14757 sgd_solver.cpp:106] Iteration 5, lr = 0.01
I1209 11:25:52.265308 14757 solver.cpp:228] Iteration 6, loss = 0.0689826
I1209 11:25:52.265329 14757 solver.cpp:244]     Train net output #0: loss = 0.0689826 (* 1 = 0.0689826 loss)
I1209 11:25:52.265338 14757 sgd_solver.cpp:106] Iteration 6, lr = 0.01
I1209 11:25:52.265745 14757 solver.cpp:228] Iteration 7, loss = 0.0652205
I1209 11:25:52.265776 14757 solver.cpp:244]     Train net output #0: loss = 0.0652205 (* 1 = 0.0652205 loss)
I1209 11:25:52.265785 14757 sgd_solver.cpp:106] Iteration 7, lr = 0.01
I1209 11:25:52.266235 14757 solver.cpp:228] Iteration 8, loss = 0.0412991
I1209 11:25:52.266257 14757 solver.cpp:244]     Train net output #0: loss = 0.0412991 (* 1 = 0.0412991 loss)
I1209 11:25:52.266265 14757 sgd_solver.cpp:106] Iteration 8, lr = 0.01
I1209 11:25:52.266682 14757 solver.cpp:228] Iteration 9, loss = 0.0439358
I1209 11:25:52.266702 14757 solver.cpp:244]     Train net output #0: loss = 0.0439358 (* 1 = 0.0439358 loss)
I1209 11:25:52.266711 14757 sgd_solver.cpp:106] Iteration 9, lr = 0.01
I1209 11:25:52.266794 14757 solver.cpp:337] Iteration 10, Testing net (#0)
I1209 11:25:52.267398 14757 solver.cpp:404]     Test net output #0: loss = 0.0467744 (* 1 = 0.0467744 loss)
I1209 11:25:52.267753 14757 solver.cpp:228] Iteration 10, loss = 0.0422129
I1209 11:25:52.267773 14757 solver.cpp:244]     Train net output #0: loss = 0.0422129 (* 1 = 0.0422129 loss)
I1209 11:25:52.267783 14757 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I1209 11:25:52.268187 14757 solver.cpp:228] Iteration 11, loss = 0.0334017
I1209 11:25:52.268208 14757 solver.cpp:244]     Train net output #0: loss = 0.0334017 (* 1 = 0.0334017 loss)
I1209 11:25:52.268216 14757 sgd_solver.cpp:106] Iteration 11, lr = 0.01
I1209 11:25:52.268622 14757 solver.cpp:228] Iteration 12, loss = 0.0368294
I1209 11:25:52.268642 14757 solver.cpp:244]     Train net output #0: loss = 0.0368294 (* 1 = 0.0368294 loss)
I1209 11:25:52.268651 14757 sgd_solver.cpp:106] Iteration 12, lr = 0.01
I1209 11:25:52.269055 14757 solver.cpp:228] Iteration 13, loss = 0.0223119
I1209 11:25:52.269075 14757 solver.cpp:244]     Train net output #0: loss = 0.0223119 (* 1 = 0.0223119 loss)
I1209 11:25:52.269084 14757 sgd_solver.cpp:106] Iteration 13, lr = 0.01
I1209 11:25:52.269493 14757 solver.cpp:228] Iteration 14, loss = 0.0281184
I1209 11:25:52.269513 14757 solver.cpp:244]     Train net output #0: loss = 0.0281184 (* 1 = 0.0281184 loss)
I1209 11:25:52.269526 14757 sgd_solver.cpp:106] Iteration 14, lr = 0.001
I1209 11:25:52.269973 14757 solver.cpp:228] Iteration 15, loss = 0.0210421
I1209 11:25:52.269994 14757 solver.cpp:244]     Train net output #0: loss = 0.0210421 (* 1 = 0.0210421 loss)
I1209 11:25:52.270004 14757 sgd_solver.cpp:106] Iteration 15, lr = 0.001
I1209 11:25:52.270434 14757 solver.cpp:228] Iteration 16, loss = 0.0176213
I1209 11:25:52.270455 14757 solver.cpp:244]     Train net output #0: loss = 0.0176213 (* 1 = 0.0176213 loss)
I1209 11:25:52.270464 14757 sgd_solver.cpp:106] Iteration 16, lr = 0.001
I1209 11:25:52.270884 14757 solver.cpp:228] Iteration 17, loss = 0.0166801
I1209 11:25:52.270905 14757 solver.cpp:244]     Train net output #0: loss = 0.0166801 (* 1 = 0.0166801 loss)
I1209 11:25:52.270915 14757 sgd_solver.cpp:106] Iteration 17, lr = 0.001
I1209 11:25:52.271339 14757 solver.cpp:228] Iteration 18, loss = 0.0109948
I1209 11:25:52.271359 14757 solver.cpp:244]     Train net output #0: loss = 0.0109948 (* 1 = 0.0109948 loss)
I1209 11:25:52.271369 14757 sgd_solver.cpp:106] Iteration 18, lr = 0.001
I1209 11:25:52.271775 14757 solver.cpp:228] Iteration 19, loss = 0.011709
I1209 11:25:52.271795 14757 solver.cpp:244]     Train net output #0: loss = 0.011709 (* 1 = 0.011709 loss)
I1209 11:25:52.271806 14757 sgd_solver.cpp:106] Iteration 19, lr = 0.001
I1209 11:25:52.271879 14757 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_20.caffemodel
I1209 11:25:52.272938 14757 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_20.solverstate
I1209 11:25:52.273929 14757 solver.cpp:337] Iteration 20, Testing net (#0)
I1209 11:25:52.274564 14757 solver.cpp:404]     Test net output #0: loss = 0.0110313 (* 1 = 0.0110313 loss)
I1209 11:25:52.274933 14757 solver.cpp:228] Iteration 20, loss = 0.00975894
I1209 11:25:52.274955 14757 solver.cpp:244]     Train net output #0: loss = 0.00975894 (* 1 = 0.00975894 loss)
I1209 11:25:52.274968 14757 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I1209 11:25:52.275377 14757 solver.cpp:228] Iteration 21, loss = 0.00714323
I1209 11:25:52.275398 14757 solver.cpp:244]     Train net output #0: loss = 0.00714323 (* 1 = 0.00714323 loss)
I1209 11:25:52.275406 14757 sgd_solver.cpp:106] Iteration 21, lr = 0.001
I1209 11:25:52.275827 14757 solver.cpp:228] Iteration 22, loss = 0.00825458
I1209 11:25:52.275848 14757 solver.cpp:244]     Train net output #0: loss = 0.00825458 (* 1 = 0.00825458 loss)
I1209 11:25:52.275858 14757 sgd_solver.cpp:106] Iteration 22, lr = 0.001
I1209 11:25:52.276263 14757 solver.cpp:228] Iteration 23, loss = 0.00498971
I1209 11:25:52.276283 14757 solver.cpp:244]     Train net output #0: loss = 0.00498971 (* 1 = 0.00498971 loss)
I1209 11:25:52.276293 14757 sgd_solver.cpp:106] Iteration 23, lr = 0.001
I1209 11:25:52.276692 14757 solver.cpp:228] Iteration 24, loss = 0.00714233
I1209 11:25:52.276713 14757 solver.cpp:244]     Train net output #0: loss = 0.00714233 (* 1 = 0.00714233 loss)
I1209 11:25:52.276722 14757 sgd_solver.cpp:106] Iteration 24, lr = 0.001
I1209 11:25:52.277127 14757 solver.cpp:228] Iteration 25, loss = 0.0049114
I1209 11:25:52.277148 14757 solver.cpp:244]     Train net output #0: loss = 0.0049114 (* 1 = 0.0049114 loss)
I1209 11:25:52.277158 14757 sgd_solver.cpp:106] Iteration 25, lr = 0.001
I1209 11:25:52.277559 14757 solver.cpp:228] Iteration 26, loss = 0.0041775
I1209 11:25:52.277580 14757 solver.cpp:244]     Train net output #0: loss = 0.0041775 (* 1 = 0.0041775 loss)
I1209 11:25:52.277590 14757 sgd_solver.cpp:106] Iteration 26, lr = 0.001
I1209 11:25:52.278033 14757 solver.cpp:228] Iteration 27, loss = 0.00458113
I1209 11:25:52.278055 14757 solver.cpp:244]     Train net output #0: loss = 0.00458113 (* 1 = 0.00458113 loss)
I1209 11:25:52.278064 14757 sgd_solver.cpp:106] Iteration 27, lr = 0.001
I1209 11:25:52.278476 14757 solver.cpp:228] Iteration 28, loss = 0.00356792
I1209 11:25:52.278496 14757 solver.cpp:244]     Train net output #0: loss = 0.00356792 (* 1 = 0.00356792 loss)
I1209 11:25:52.278506 14757 sgd_solver.cpp:106] Iteration 28, lr = 0.0001
I1209 11:25:52.278921 14757 solver.cpp:228] Iteration 29, loss = 0.00413778
I1209 11:25:52.278941 14757 solver.cpp:244]     Train net output #0: loss = 0.00413778 (* 1 = 0.00413778 loss)
I1209 11:25:52.278951 14757 sgd_solver.cpp:106] Iteration 29, lr = 0.0001
I1209 11:25:52.279034 14757 solver.cpp:337] Iteration 30, Testing net (#0)
I1209 11:25:52.279638 14757 solver.cpp:404]     Test net output #0: loss = 0.0035085 (* 1 = 0.0035085 loss)
I1209 11:25:52.280025 14757 solver.cpp:228] Iteration 30, loss = 0.00305322
I1209 11:25:52.280045 14757 solver.cpp:244]     Train net output #0: loss = 0.00305322 (* 1 = 0.00305322 loss)
I1209 11:25:52.280055 14757 sgd_solver.cpp:106] Iteration 30, lr = 0.0001
I1209 11:25:52.280467 14757 solver.cpp:228] Iteration 31, loss = 0.00212924
I1209 11:25:52.280488 14757 solver.cpp:244]     Train net output #0: loss = 0.00212924 (* 1 = 0.00212924 loss)
I1209 11:25:52.280498 14757 sgd_solver.cpp:106] Iteration 31, lr = 0.0001
I1209 11:25:52.280910 14757 solver.cpp:228] Iteration 32, loss = 0.00270817
I1209 11:25:52.280930 14757 solver.cpp:244]     Train net output #0: loss = 0.00270817 (* 1 = 0.00270817 loss)
I1209 11:25:52.280938 14757 sgd_solver.cpp:106] Iteration 32, lr = 0.0001
I1209 11:25:52.281342 14757 solver.cpp:228] Iteration 33, loss = 0.00167077
I1209 11:25:52.281363 14757 solver.cpp:244]     Train net output #0: loss = 0.00167077 (* 1 = 0.00167077 loss)
I1209 11:25:52.281371 14757 sgd_solver.cpp:106] Iteration 33, lr = 0.0001
I1209 11:25:52.281788 14757 solver.cpp:228] Iteration 34, loss = 0.00280396
I1209 11:25:52.281810 14757 solver.cpp:244]     Train net output #0: loss = 0.00280396 (* 1 = 0.00280396 loss)
I1209 11:25:52.281818 14757 sgd_solver.cpp:106] Iteration 34, lr = 0.0001
I1209 11:25:52.282243 14757 solver.cpp:228] Iteration 35, loss = 0.00176553
I1209 11:25:52.282263 14757 solver.cpp:244]     Train net output #0: loss = 0.00176553 (* 1 = 0.00176553 loss)
I1209 11:25:52.282277 14757 sgd_solver.cpp:106] Iteration 35, lr = 0.0001
I1209 11:25:52.282681 14757 solver.cpp:228] Iteration 36, loss = 0.00153824
I1209 11:25:52.282701 14757 solver.cpp:244]     Train net output #0: loss = 0.00153824 (* 1 = 0.00153824 loss)
I1209 11:25:52.282711 14757 sgd_solver.cpp:106] Iteration 36, lr = 0.0001
I1209 11:25:52.283114 14757 solver.cpp:228] Iteration 37, loss = 0.00202055
I1209 11:25:52.283134 14757 solver.cpp:244]     Train net output #0: loss = 0.00202055 (* 1 = 0.00202055 loss)
I1209 11:25:52.283144 14757 sgd_solver.cpp:106] Iteration 37, lr = 0.0001
I1209 11:25:52.283558 14757 solver.cpp:228] Iteration 38, loss = 0.00185872
I1209 11:25:52.283578 14757 solver.cpp:244]     Train net output #0: loss = 0.00185872 (* 1 = 0.00185872 loss)
I1209 11:25:52.283587 14757 sgd_solver.cpp:106] Iteration 38, lr = 0.0001
I1209 11:25:52.283993 14757 solver.cpp:228] Iteration 39, loss = 0.00232535
I1209 11:25:52.284013 14757 solver.cpp:244]     Train net output #0: loss = 0.00232535 (* 1 = 0.00232535 loss)
I1209 11:25:52.284023 14757 sgd_solver.cpp:106] Iteration 39, lr = 0.0001
I1209 11:25:52.284093 14757 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_40.caffemodel
I1209 11:25:52.284847 14757 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_40.solverstate
I1209 11:25:52.285822 14757 solver.cpp:317] Iteration 40, loss = 0.00158099
I1209 11:25:52.285845 14757 solver.cpp:337] Iteration 40, Testing net (#0)
I1209 11:25:52.286506 14757 solver.cpp:404]     Test net output #0: loss = 0.00183769 (* 1 = 0.00183769 loss)
I1209 11:25:52.286525 14757 solver.cpp:322] Optimization Done.
I1209 11:25:52.286530 14757 caffe.cpp:254] Optimization Done.
