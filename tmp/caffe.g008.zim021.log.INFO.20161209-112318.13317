Log file created at: 2016/12/09 11:23:18
Running on machine: g008
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1209 11:23:18.407392 13317 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112317-73c0/solver.prototxt
I1209 11:23:18.408959 13317 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W1209 11:23:18.408970 13317 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I1209 11:23:18.409793 13317 caffe.cpp:217] Using GPUs 0
I1209 11:23:18.455739 13317 caffe.cpp:222] GPU 0: Tesla K20m
I1209 11:23:18.844475 13317 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 9
base_lr: 0.01
display: 1
max_iter: 27
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 9
snapshot: 9
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 3405691582
net: "train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
type: "SGD"
I1209 11:23:18.845881 13317 solver.cpp:91] Creating training net from net file: train_val.prototxt
I1209 11:23:18.847005 13317 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1209 11:23:18.847024 13317 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I1209 11:23:18.847046 13317 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/mean.binaryproto"
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/features"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/labels"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "identity"
  type: "Power"
  bottom: "data"
  top: "output"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "output"
  bottom: "label"
  top: "loss"
}
I1209 11:23:18.847249 13317 layer_factory.hpp:77] Creating layer data
I1209 11:23:18.847425 13317 net.cpp:100] Creating Layer data
I1209 11:23:18.847466 13317 net.cpp:408] data -> data
I1209 11:23:18.847532 13317 data_transformer.cpp:25] Loading mean file from: /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/mean.binaryproto
I1209 11:23:18.850123 13322 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/features
I1209 11:23:18.867821 13317 data_layer.cpp:41] output data size: 10,1,32,32
I1209 11:23:18.868827 13317 net.cpp:150] Setting up data
I1209 11:23:18.868847 13317 net.cpp:157] Top shape: 10 1 32 32 (10240)
I1209 11:23:18.868896 13317 net.cpp:165] Memory required for data: 40960
I1209 11:23:18.868926 13317 layer_factory.hpp:77] Creating layer label
I1209 11:23:18.869020 13317 net.cpp:100] Creating Layer label
I1209 11:23:18.869038 13317 net.cpp:408] label -> label
I1209 11:23:18.873644 13324 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/labels
I1209 11:23:18.874282 13317 data_layer.cpp:41] output data size: 10,1,32,32
I1209 11:23:18.874506 13317 net.cpp:150] Setting up label
I1209 11:23:18.874522 13317 net.cpp:157] Top shape: 10 1 32 32 (10240)
I1209 11:23:18.874533 13317 net.cpp:165] Memory required for data: 81920
I1209 11:23:18.874541 13317 layer_factory.hpp:77] Creating layer identity
I1209 11:23:18.874558 13317 net.cpp:100] Creating Layer identity
I1209 11:23:18.874567 13317 net.cpp:434] identity <- data
I1209 11:23:18.874593 13317 net.cpp:408] identity -> output
I1209 11:23:18.874649 13317 net.cpp:150] Setting up identity
I1209 11:23:18.874660 13317 net.cpp:157] Top shape: 10 1 32 32 (10240)
I1209 11:23:18.874668 13317 net.cpp:165] Memory required for data: 122880
I1209 11:23:18.874675 13317 layer_factory.hpp:77] Creating layer loss
I1209 11:23:18.874685 13317 net.cpp:100] Creating Layer loss
I1209 11:23:18.874689 13317 net.cpp:434] loss <- output
I1209 11:23:18.874701 13317 net.cpp:434] loss <- label
I1209 11:23:18.874711 13317 net.cpp:408] loss -> loss
I1209 11:23:18.874778 13317 net.cpp:150] Setting up loss
I1209 11:23:18.874788 13317 net.cpp:157] Top shape: (1)
I1209 11:23:18.874797 13317 net.cpp:160]     with loss weight 1
I1209 11:23:18.874830 13317 net.cpp:165] Memory required for data: 122884
I1209 11:23:18.874840 13317 net.cpp:228] loss does not need backward computation.
I1209 11:23:18.874847 13317 net.cpp:228] identity does not need backward computation.
I1209 11:23:18.874853 13317 net.cpp:228] label does not need backward computation.
I1209 11:23:18.874858 13317 net.cpp:228] data does not need backward computation.
I1209 11:23:18.874863 13317 net.cpp:270] This network produces output loss
I1209 11:23:18.874873 13317 net.cpp:283] Network initialization done.
I1209 11:23:18.875375 13317 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I1209 11:23:18.875413 13317 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1209 11:23:18.875421 13317 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I1209 11:23:18.875432 13317 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/mean.binaryproto"
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/val_db/features"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/val_db/labels"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "identity"
  type: "Power"
  bottom: "data"
  top: "output"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "output"
  bottom: "label"
  top: "loss"
}
I1209 11:23:18.875546 13317 layer_factory.hpp:77] Creating layer data
I1209 11:23:18.875646 13317 net.cpp:100] Creating Layer data
I1209 11:23:18.875663 13317 net.cpp:408] data -> data
I1209 11:23:18.875679 13317 data_transformer.cpp:25] Loading mean file from: /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/train_db/mean.binaryproto
I1209 11:23:18.878713 13326 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/val_db/features
I1209 11:23:18.878945 13317 data_layer.cpp:41] output data size: 10,1,32,32
I1209 11:23:18.879160 13317 net.cpp:150] Setting up data
I1209 11:23:18.879175 13317 net.cpp:157] Top shape: 10 1 32 32 (10240)
I1209 11:23:18.879186 13317 net.cpp:165] Memory required for data: 40960
I1209 11:23:18.879194 13317 layer_factory.hpp:77] Creating layer label
I1209 11:23:18.879284 13317 net.cpp:100] Creating Layer label
I1209 11:23:18.879299 13317 net.cpp:408] label -> label
I1209 11:23:18.882398 13328 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112313-cd27/val_db/labels
I1209 11:23:18.882643 13317 data_layer.cpp:41] output data size: 10,1,32,32
I1209 11:23:18.882882 13317 net.cpp:150] Setting up label
I1209 11:23:18.882899 13317 net.cpp:157] Top shape: 10 1 32 32 (10240)
I1209 11:23:18.882910 13317 net.cpp:165] Memory required for data: 81920
I1209 11:23:18.882917 13317 layer_factory.hpp:77] Creating layer identity
I1209 11:23:18.882930 13317 net.cpp:100] Creating Layer identity
I1209 11:23:18.882936 13317 net.cpp:434] identity <- data
I1209 11:23:18.882946 13317 net.cpp:408] identity -> output
I1209 11:23:18.883067 13317 net.cpp:150] Setting up identity
I1209 11:23:18.883090 13317 net.cpp:157] Top shape: 10 1 32 32 (10240)
I1209 11:23:18.883108 13317 net.cpp:165] Memory required for data: 122880
I1209 11:23:18.883116 13317 layer_factory.hpp:77] Creating layer loss
I1209 11:23:18.883126 13317 net.cpp:100] Creating Layer loss
I1209 11:23:18.883132 13317 net.cpp:434] loss <- output
I1209 11:23:18.883143 13317 net.cpp:434] loss <- label
I1209 11:23:18.883152 13317 net.cpp:408] loss -> loss
I1209 11:23:18.883219 13317 net.cpp:150] Setting up loss
I1209 11:23:18.883229 13317 net.cpp:157] Top shape: (1)
I1209 11:23:18.883237 13317 net.cpp:160]     with loss weight 1
I1209 11:23:18.883247 13317 net.cpp:165] Memory required for data: 122884
I1209 11:23:18.883254 13317 net.cpp:228] loss does not need backward computation.
I1209 11:23:18.883260 13317 net.cpp:228] identity does not need backward computation.
I1209 11:23:18.883265 13317 net.cpp:228] label does not need backward computation.
I1209 11:23:18.883270 13317 net.cpp:228] data does not need backward computation.
I1209 11:23:18.883275 13317 net.cpp:270] This network produces output loss
I1209 11:23:18.883282 13317 net.cpp:283] Network initialization done.
I1209 11:23:18.883314 13317 solver.cpp:60] Solver scaffolding done.
I1209 11:23:18.883333 13317 caffe.cpp:251] Starting Optimization
I1209 11:23:18.883342 13317 solver.cpp:279] Solving 
I1209 11:23:18.883347 13317 solver.cpp:280] Learning Rate Policy: step
I1209 11:23:18.883358 13317 solver.cpp:337] Iteration 0, Testing net (#0)
I1209 11:23:18.883484 13317 blocking_queue.cpp:50] Data layer prefetch queue empty
I1209 11:23:18.884742 13317 solver.cpp:404]     Test net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.885449 13317 solver.cpp:228] Iteration 0, loss = 8.25795e+06
I1209 11:23:18.885475 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.885505 13317 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1209 11:23:18.885767 13317 solver.cpp:228] Iteration 1, loss = 8.25795e+06
I1209 11:23:18.885792 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.885804 13317 sgd_solver.cpp:106] Iteration 1, lr = 0.01
I1209 11:23:18.886080 13317 solver.cpp:228] Iteration 2, loss = 8.25795e+06
I1209 11:23:18.886102 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.886114 13317 sgd_solver.cpp:106] Iteration 2, lr = 0.01
I1209 11:23:18.886348 13317 solver.cpp:228] Iteration 3, loss = 8.25795e+06
I1209 11:23:18.886370 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.886381 13317 sgd_solver.cpp:106] Iteration 3, lr = 0.01
I1209 11:23:18.886620 13317 solver.cpp:228] Iteration 4, loss = 8.25795e+06
I1209 11:23:18.886642 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.886652 13317 sgd_solver.cpp:106] Iteration 4, lr = 0.01
I1209 11:23:18.886914 13317 solver.cpp:228] Iteration 5, loss = 8.25795e+06
I1209 11:23:18.886935 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.886945 13317 sgd_solver.cpp:106] Iteration 5, lr = 0.01
I1209 11:23:18.887171 13317 solver.cpp:228] Iteration 6, loss = 8.25795e+06
I1209 11:23:18.887192 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.887203 13317 sgd_solver.cpp:106] Iteration 6, lr = 0.01
I1209 11:23:18.887467 13317 solver.cpp:228] Iteration 7, loss = 8.25795e+06
I1209 11:23:18.887490 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.887500 13317 sgd_solver.cpp:106] Iteration 7, lr = 0.01
I1209 11:23:18.887846 13317 solver.cpp:228] Iteration 8, loss = 8.25795e+06
I1209 11:23:18.887868 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.887879 13317 sgd_solver.cpp:106] Iteration 8, lr = 0.01
I1209 11:23:18.887894 13317 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_9.caffemodel
I1209 11:23:18.888557 13317 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9.solverstate
I1209 11:23:18.889008 13317 solver.cpp:337] Iteration 9, Testing net (#0)
I1209 11:23:18.889292 13317 solver.cpp:404]     Test net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.889580 13317 solver.cpp:228] Iteration 9, loss = 8.25795e+06
I1209 11:23:18.889601 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.889616 13317 sgd_solver.cpp:106] Iteration 9, lr = 0.001
I1209 11:23:18.889879 13317 solver.cpp:228] Iteration 10, loss = 8.25795e+06
I1209 11:23:18.889902 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.889914 13317 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I1209 11:23:18.890146 13317 solver.cpp:228] Iteration 11, loss = 8.25795e+06
I1209 11:23:18.890167 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.890177 13317 sgd_solver.cpp:106] Iteration 11, lr = 0.001
I1209 11:23:18.890417 13317 solver.cpp:228] Iteration 12, loss = 8.25795e+06
I1209 11:23:18.890439 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.890450 13317 sgd_solver.cpp:106] Iteration 12, lr = 0.001
I1209 11:23:18.890702 13317 solver.cpp:228] Iteration 13, loss = 8.25795e+06
I1209 11:23:18.890723 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.890733 13317 sgd_solver.cpp:106] Iteration 13, lr = 0.001
I1209 11:23:18.890966 13317 solver.cpp:228] Iteration 14, loss = 8.25795e+06
I1209 11:23:18.890987 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.890997 13317 sgd_solver.cpp:106] Iteration 14, lr = 0.001
I1209 11:23:18.891230 13317 solver.cpp:228] Iteration 15, loss = 8.25795e+06
I1209 11:23:18.891252 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.891263 13317 sgd_solver.cpp:106] Iteration 15, lr = 0.001
I1209 11:23:18.891592 13317 solver.cpp:228] Iteration 16, loss = 8.25795e+06
I1209 11:23:18.891614 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.891624 13317 sgd_solver.cpp:106] Iteration 16, lr = 0.001
I1209 11:23:18.891976 13317 solver.cpp:228] Iteration 17, loss = 8.25795e+06
I1209 11:23:18.891999 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.892012 13317 sgd_solver.cpp:106] Iteration 17, lr = 0.001
I1209 11:23:18.892025 13317 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_18.caffemodel
I1209 11:23:18.892524 13317 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_18.solverstate
I1209 11:23:18.892880 13317 solver.cpp:337] Iteration 18, Testing net (#0)
I1209 11:23:18.893148 13317 solver.cpp:404]     Test net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.893414 13317 solver.cpp:228] Iteration 18, loss = 8.25795e+06
I1209 11:23:18.893436 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.893447 13317 sgd_solver.cpp:106] Iteration 18, lr = 0.0001
I1209 11:23:18.893718 13317 solver.cpp:228] Iteration 19, loss = 8.25795e+06
I1209 11:23:18.893739 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.893750 13317 sgd_solver.cpp:106] Iteration 19, lr = 0.0001
I1209 11:23:18.893999 13317 solver.cpp:228] Iteration 20, loss = 8.25795e+06
I1209 11:23:18.894024 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.894034 13317 sgd_solver.cpp:106] Iteration 20, lr = 0.0001
I1209 11:23:18.894258 13317 solver.cpp:228] Iteration 21, loss = 8.25795e+06
I1209 11:23:18.894279 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.894289 13317 sgd_solver.cpp:106] Iteration 21, lr = 0.0001
I1209 11:23:18.894557 13317 solver.cpp:228] Iteration 22, loss = 8.25795e+06
I1209 11:23:18.894579 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.894589 13317 sgd_solver.cpp:106] Iteration 22, lr = 0.0001
I1209 11:23:18.894816 13317 solver.cpp:228] Iteration 23, loss = 8.25795e+06
I1209 11:23:18.894839 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.894848 13317 sgd_solver.cpp:106] Iteration 23, lr = 0.0001
I1209 11:23:18.895097 13317 solver.cpp:228] Iteration 24, loss = 8.25795e+06
I1209 11:23:18.895119 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.895129 13317 sgd_solver.cpp:106] Iteration 24, lr = 0.0001
I1209 11:23:18.895465 13317 solver.cpp:228] Iteration 25, loss = 8.25795e+06
I1209 11:23:18.895488 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.895498 13317 sgd_solver.cpp:106] Iteration 25, lr = 0.0001
I1209 11:23:18.895851 13317 solver.cpp:228] Iteration 26, loss = 8.25795e+06
I1209 11:23:18.895872 13317 solver.cpp:244]     Train net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.895882 13317 sgd_solver.cpp:106] Iteration 26, lr = 0.0001
I1209 11:23:18.895895 13317 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_27.caffemodel
I1209 11:23:18.896284 13317 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_27.solverstate
I1209 11:23:18.896885 13317 solver.cpp:317] Iteration 27, loss = 8.25795e+06
I1209 11:23:18.896904 13317 solver.cpp:337] Iteration 27, Testing net (#0)
I1209 11:23:18.897130 13317 solver.cpp:404]     Test net output #0: loss = 8.25795e+06 (* 1 = 8.25795e+06 loss)
I1209 11:23:18.897146 13317 solver.cpp:322] Optimization Done.
I1209 11:23:18.897151 13317 caffe.cpp:254] Optimization Done.
