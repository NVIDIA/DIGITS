Log file created at: 2016/12/09 11:25:41
Running on machine: g008
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1209 11:25:41.088801 14414 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /data/zim021/digits-proj/DIGITS/tmp/tmpyzXVAu/20161209-112540-2f7b/solver.prototxt
I1209 11:25:41.090162 14414 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W1209 11:25:41.090174 14414 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I1209 11:25:41.091086 14414 caffe.cpp:217] Using GPUs 0
I1209 11:25:41.134574 14414 caffe.cpp:222] GPU 0: Tesla K20m
I1209 11:25:41.554271 14414 solver.cpp:48] Initializing solver from parameters: 
test_iter: 20
test_interval: 100
base_lr: 0.01
display: 12
max_iter: 300
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
stepsize: 99
snapshot: 100
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
random_seed: 3405691582
net: "train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
type: "SGD"
I1209 11:25:41.555749 14414 solver.cpp:91] Creating training net from net file: train_val.prototxt
I1209 11:25:41.556860 14414 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1209 11:25:41.556876 14414 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I1209 11:25:41.556900 14414 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto"
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_images"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_labels"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "scale"
  type: "Power"
  bottom: "data"
  top: "scale"
  power_param {
    scale: 0.004
  }
}
layer {
  name: "hidden"
  type: "InnerProduct"
  bottom: "scale"
  top: "output"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "output"
  bottom: "label"
  top: "loss"
}
I1209 11:25:41.557124 14414 layer_factory.hpp:77] Creating layer data
I1209 11:25:41.557291 14414 net.cpp:100] Creating Layer data
I1209 11:25:41.557337 14414 net.cpp:408] data -> data
I1209 11:25:41.557397 14414 data_transformer.cpp:25] Loading mean file from: /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto
I1209 11:25:41.559856 14420 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_images
I1209 11:25:41.581868 14414 data_layer.cpp:41] output data size: 1,1,10,10
I1209 11:25:41.582432 14414 net.cpp:150] Setting up data
I1209 11:25:41.582450 14414 net.cpp:157] Top shape: 1 1 10 10 (100)
I1209 11:25:41.582496 14414 net.cpp:165] Memory required for data: 400
I1209 11:25:41.582535 14414 layer_factory.hpp:77] Creating layer label
I1209 11:25:41.582617 14414 net.cpp:100] Creating Layer label
I1209 11:25:41.582635 14414 net.cpp:408] label -> label
I1209 11:25:41.586370 14422 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_labels
I1209 11:25:41.586560 14414 data_layer.cpp:41] output data size: 1,1,1,2
I1209 11:25:41.587025 14414 net.cpp:150] Setting up label
I1209 11:25:41.587040 14414 net.cpp:157] Top shape: 1 1 1 2 (2)
I1209 11:25:41.587051 14414 net.cpp:165] Memory required for data: 408
I1209 11:25:41.587059 14414 layer_factory.hpp:77] Creating layer scale
I1209 11:25:41.587076 14414 net.cpp:100] Creating Layer scale
I1209 11:25:41.587085 14414 net.cpp:434] scale <- data
I1209 11:25:41.587106 14414 net.cpp:408] scale -> scale
I1209 11:25:41.587239 14414 net.cpp:150] Setting up scale
I1209 11:25:41.587252 14414 net.cpp:157] Top shape: 1 1 10 10 (100)
I1209 11:25:41.587261 14414 net.cpp:165] Memory required for data: 808
I1209 11:25:41.587268 14414 layer_factory.hpp:77] Creating layer hidden
I1209 11:25:41.587293 14414 net.cpp:100] Creating Layer hidden
I1209 11:25:41.587301 14414 net.cpp:434] hidden <- scale
I1209 11:25:41.587314 14414 net.cpp:408] hidden -> output
I1209 11:25:41.587496 14414 net.cpp:150] Setting up hidden
I1209 11:25:41.587508 14414 net.cpp:157] Top shape: 1 2 (2)
I1209 11:25:41.587517 14414 net.cpp:165] Memory required for data: 816
I1209 11:25:41.587546 14414 layer_factory.hpp:77] Creating layer loss
I1209 11:25:41.587575 14414 net.cpp:100] Creating Layer loss
I1209 11:25:41.587584 14414 net.cpp:434] loss <- output
I1209 11:25:41.587590 14414 net.cpp:434] loss <- label
I1209 11:25:41.587600 14414 net.cpp:408] loss -> loss
I1209 11:25:41.587661 14414 net.cpp:150] Setting up loss
I1209 11:25:41.587671 14414 net.cpp:157] Top shape: (1)
I1209 11:25:41.587680 14414 net.cpp:160]     with loss weight 1
I1209 11:25:41.587713 14414 net.cpp:165] Memory required for data: 820
I1209 11:25:41.587723 14414 net.cpp:226] loss needs backward computation.
I1209 11:25:41.587730 14414 net.cpp:226] hidden needs backward computation.
I1209 11:25:41.587736 14414 net.cpp:228] scale does not need backward computation.
I1209 11:25:41.587743 14414 net.cpp:228] label does not need backward computation.
I1209 11:25:41.587748 14414 net.cpp:228] data does not need backward computation.
I1209 11:25:41.587752 14414 net.cpp:270] This network produces output loss
I1209 11:25:41.587762 14414 net.cpp:283] Network initialization done.
I1209 11:25:41.588357 14414 solver.cpp:181] Creating test net (#0) specified by net file: train_val.prototxt
I1209 11:25:41.588393 14414 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1209 11:25:41.588402 14414 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I1209 11:25:41.588413 14414 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto"
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_images"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "/data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_labels"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "scale"
  type: "Power"
  bottom: "data"
  top: "scale"
  power_param {
    scale: 0.004
  }
}
layer {
  name: "hidden"
  type: "InnerProduct"
  bottom: "scale"
  top: "output"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "output"
  bottom: "label"
  top: "loss"
}
I1209 11:25:41.588548 14414 layer_factory.hpp:77] Creating layer data
I1209 11:25:41.588626 14414 net.cpp:100] Creating Layer data
I1209 11:25:41.588644 14414 net.cpp:408] data -> data
I1209 11:25:41.588660 14414 data_transformer.cpp:25] Loading mean file from: /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/train_mean.binaryproto
I1209 11:25:41.591076 14424 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_images
I1209 11:25:41.591301 14414 data_layer.cpp:41] output data size: 1,1,10,10
I1209 11:25:41.591747 14414 net.cpp:150] Setting up data
I1209 11:25:41.591763 14414 net.cpp:157] Top shape: 1 1 10 10 (100)
I1209 11:25:41.591783 14414 net.cpp:165] Memory required for data: 400
I1209 11:25:41.591790 14414 layer_factory.hpp:77] Creating layer label
I1209 11:25:41.591886 14414 net.cpp:100] Creating Layer label
I1209 11:25:41.591900 14414 net.cpp:408] label -> label
I1209 11:25:41.594681 14426 db_lmdb.cpp:35] Opened lmdb /data/zim021/digits-proj/DIGITS/tmp/tmpc2ZVI7/val_labels
I1209 11:25:41.594873 14414 data_layer.cpp:41] output data size: 1,1,1,2
I1209 11:25:41.595293 14414 net.cpp:150] Setting up label
I1209 11:25:41.595309 14414 net.cpp:157] Top shape: 1 1 1 2 (2)
I1209 11:25:41.595319 14414 net.cpp:165] Memory required for data: 408
I1209 11:25:41.595327 14414 layer_factory.hpp:77] Creating layer scale
I1209 11:25:41.595345 14414 net.cpp:100] Creating Layer scale
I1209 11:25:41.595352 14414 net.cpp:434] scale <- data
I1209 11:25:41.595366 14414 net.cpp:408] scale -> scale
I1209 11:25:41.595408 14414 net.cpp:150] Setting up scale
I1209 11:25:41.595418 14414 net.cpp:157] Top shape: 1 1 10 10 (100)
I1209 11:25:41.595427 14414 net.cpp:165] Memory required for data: 808
I1209 11:25:41.595433 14414 layer_factory.hpp:77] Creating layer hidden
I1209 11:25:41.595443 14414 net.cpp:100] Creating Layer hidden
I1209 11:25:41.595448 14414 net.cpp:434] hidden <- scale
I1209 11:25:41.595461 14414 net.cpp:408] hidden -> output
I1209 11:25:41.595603 14414 net.cpp:150] Setting up hidden
I1209 11:25:41.595614 14414 net.cpp:157] Top shape: 1 2 (2)
I1209 11:25:41.595623 14414 net.cpp:165] Memory required for data: 816
I1209 11:25:41.595639 14414 layer_factory.hpp:77] Creating layer loss
I1209 11:25:41.595650 14414 net.cpp:100] Creating Layer loss
I1209 11:25:41.595656 14414 net.cpp:434] loss <- output
I1209 11:25:41.595662 14414 net.cpp:434] loss <- label
I1209 11:25:41.595670 14414 net.cpp:408] loss -> loss
I1209 11:25:41.595723 14414 net.cpp:150] Setting up loss
I1209 11:25:41.595734 14414 net.cpp:157] Top shape: (1)
I1209 11:25:41.595748 14414 net.cpp:160]     with loss weight 1
I1209 11:25:41.595757 14414 net.cpp:165] Memory required for data: 820
I1209 11:25:41.595764 14414 net.cpp:226] loss needs backward computation.
I1209 11:25:41.595770 14414 net.cpp:226] hidden needs backward computation.
I1209 11:25:41.595777 14414 net.cpp:228] scale does not need backward computation.
I1209 11:25:41.595782 14414 net.cpp:228] label does not need backward computation.
I1209 11:25:41.595787 14414 net.cpp:228] data does not need backward computation.
I1209 11:25:41.595790 14414 net.cpp:270] This network produces output loss
I1209 11:25:41.595799 14414 net.cpp:283] Network initialization done.
I1209 11:25:41.595836 14414 solver.cpp:60] Solver scaffolding done.
I1209 11:25:41.595968 14414 caffe.cpp:251] Starting Optimization
I1209 11:25:41.595981 14414 solver.cpp:279] Solving 
I1209 11:25:41.595986 14414 solver.cpp:280] Learning Rate Policy: step
I1209 11:25:41.596113 14414 solver.cpp:337] Iteration 0, Testing net (#0)
I1209 11:25:41.596395 14414 blocking_queue.cpp:50] Data layer prefetch queue empty
I1209 11:25:41.602352 14414 solver.cpp:404]     Test net output #0: loss = 0.0933352 (* 1 = 0.0933352 loss)
I1209 11:25:41.603003 14414 solver.cpp:228] Iteration 0, loss = 0.0441272
I1209 11:25:41.603027 14414 solver.cpp:244]     Train net output #0: loss = 0.0441272 (* 1 = 0.0441272 loss)
I1209 11:25:41.603055 14414 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1209 11:25:41.608130 14414 solver.cpp:228] Iteration 12, loss = 0.0201091
I1209 11:25:41.608161 14414 solver.cpp:244]     Train net output #0: loss = 0.0201091 (* 1 = 0.0201091 loss)
I1209 11:25:41.608175 14414 sgd_solver.cpp:106] Iteration 12, lr = 0.01
I1209 11:25:41.612783 14414 solver.cpp:228] Iteration 24, loss = 0.0285253
I1209 11:25:41.612805 14414 solver.cpp:244]     Train net output #0: loss = 0.0285253 (* 1 = 0.0285253 loss)
I1209 11:25:41.612815 14414 sgd_solver.cpp:106] Iteration 24, lr = 0.01
I1209 11:25:41.617411 14414 solver.cpp:228] Iteration 36, loss = 0.00320822
I1209 11:25:41.617434 14414 solver.cpp:244]     Train net output #0: loss = 0.00320821 (* 1 = 0.00320821 loss)
I1209 11:25:41.617444 14414 sgd_solver.cpp:106] Iteration 36, lr = 0.01
I1209 11:25:41.622035 14414 solver.cpp:228] Iteration 48, loss = 0.00434022
I1209 11:25:41.622056 14414 solver.cpp:244]     Train net output #0: loss = 0.00434022 (* 1 = 0.00434022 loss)
I1209 11:25:41.622066 14414 sgd_solver.cpp:106] Iteration 48, lr = 0.01
I1209 11:25:41.626662 14414 solver.cpp:228] Iteration 60, loss = 0.000210139
I1209 11:25:41.626684 14414 solver.cpp:244]     Train net output #0: loss = 0.000210136 (* 1 = 0.000210136 loss)
I1209 11:25:41.626694 14414 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I1209 11:25:41.631268 14414 solver.cpp:228] Iteration 72, loss = 2.38661e-05
I1209 11:25:41.631290 14414 solver.cpp:244]     Train net output #0: loss = 2.38639e-05 (* 1 = 2.38639e-05 loss)
I1209 11:25:41.631300 14414 sgd_solver.cpp:106] Iteration 72, lr = 0.01
I1209 11:25:41.635937 14414 solver.cpp:228] Iteration 84, loss = 8.91596e-08
I1209 11:25:41.635959 14414 solver.cpp:244]     Train net output #0: loss = 8.69526e-08 (* 1 = 8.69526e-08 loss)
I1209 11:25:41.635969 14414 sgd_solver.cpp:106] Iteration 84, lr = 0.01
I1209 11:25:41.640557 14414 solver.cpp:228] Iteration 96, loss = 8.68963e-05
I1209 11:25:41.640578 14414 solver.cpp:244]     Train net output #0: loss = 8.68941e-05 (* 1 = 8.68941e-05 loss)
I1209 11:25:41.640588 14414 sgd_solver.cpp:106] Iteration 96, lr = 0.01
I1209 11:25:41.641826 14414 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_100.caffemodel
I1209 11:25:41.643052 14414 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_100.solverstate
I1209 11:25:41.643790 14414 solver.cpp:337] Iteration 100, Testing net (#0)
I1209 11:25:41.649194 14414 solver.cpp:404]     Test net output #0: loss = 2.9403e-05 (* 1 = 2.9403e-05 loss)
I1209 11:25:41.652609 14414 solver.cpp:228] Iteration 108, loss = 2.54536e-05
I1209 11:25:41.652632 14414 solver.cpp:244]     Train net output #0: loss = 2.54514e-05 (* 1 = 2.54514e-05 loss)
I1209 11:25:41.652642 14414 sgd_solver.cpp:106] Iteration 108, lr = 0.001
I1209 11:25:41.657225 14414 solver.cpp:228] Iteration 120, loss = 5.30695e-06
I1209 11:25:41.657248 14414 solver.cpp:244]     Train net output #0: loss = 5.30475e-06 (* 1 = 5.30475e-06 loss)
I1209 11:25:41.657258 14414 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I1209 11:25:41.661830 14414 solver.cpp:228] Iteration 132, loss = 1.78455e-05
I1209 11:25:41.661854 14414 solver.cpp:244]     Train net output #0: loss = 1.78432e-05 (* 1 = 1.78432e-05 loss)
I1209 11:25:41.661862 14414 sgd_solver.cpp:106] Iteration 132, lr = 0.001
I1209 11:25:41.666484 14414 solver.cpp:228] Iteration 144, loss = 2.01062e-06
I1209 11:25:41.666507 14414 solver.cpp:244]     Train net output #0: loss = 2.00842e-06 (* 1 = 2.00842e-06 loss)
I1209 11:25:41.666517 14414 sgd_solver.cpp:106] Iteration 144, lr = 0.001
I1209 11:25:41.671144 14414 solver.cpp:228] Iteration 156, loss = 1.25524e-06
I1209 11:25:41.671166 14414 solver.cpp:244]     Train net output #0: loss = 1.25303e-06 (* 1 = 1.25303e-06 loss)
I1209 11:25:41.671176 14414 sgd_solver.cpp:106] Iteration 156, lr = 0.001
I1209 11:25:41.675698 14414 solver.cpp:228] Iteration 168, loss = 1.14405e-05
I1209 11:25:41.675720 14414 solver.cpp:244]     Train net output #0: loss = 1.14382e-05 (* 1 = 1.14382e-05 loss)
I1209 11:25:41.675729 14414 sgd_solver.cpp:106] Iteration 168, lr = 0.001
I1209 11:25:41.680377 14414 solver.cpp:228] Iteration 180, loss = 1.30461e-06
I1209 11:25:41.680399 14414 solver.cpp:244]     Train net output #0: loss = 1.3024e-06 (* 1 = 1.3024e-06 loss)
I1209 11:25:41.680409 14414 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I1209 11:25:41.685000 14414 solver.cpp:228] Iteration 192, loss = 5.22661e-07
I1209 11:25:41.685022 14414 solver.cpp:244]     Train net output #0: loss = 5.20451e-07 (* 1 = 5.20451e-07 loss)
I1209 11:25:41.685032 14414 sgd_solver.cpp:106] Iteration 192, lr = 0.001
I1209 11:25:41.687811 14414 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_200.caffemodel
I1209 11:25:41.688735 14414 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_200.solverstate
I1209 11:25:41.689420 14414 solver.cpp:337] Iteration 200, Testing net (#0)
I1209 11:25:41.694946 14414 solver.cpp:404]     Test net output #0: loss = 3.14147e-06 (* 1 = 3.14147e-06 loss)
I1209 11:25:41.696828 14414 solver.cpp:228] Iteration 204, loss = 1.17829e-06
I1209 11:25:41.696851 14414 solver.cpp:244]     Train net output #0: loss = 1.17608e-06 (* 1 = 1.17608e-06 loss)
I1209 11:25:41.696861 14414 sgd_solver.cpp:106] Iteration 204, lr = 0.0001
I1209 11:25:41.701490 14414 solver.cpp:228] Iteration 216, loss = 3.42255e-06
I1209 11:25:41.701513 14414 solver.cpp:244]     Train net output #0: loss = 3.42034e-06 (* 1 = 3.42034e-06 loss)
I1209 11:25:41.701522 14414 sgd_solver.cpp:106] Iteration 216, lr = 0.0001
I1209 11:25:41.706105 14414 solver.cpp:228] Iteration 228, loss = 3.44464e-06
I1209 11:25:41.706133 14414 solver.cpp:244]     Train net output #0: loss = 3.44243e-06 (* 1 = 3.44243e-06 loss)
I1209 11:25:41.706143 14414 sgd_solver.cpp:106] Iteration 228, lr = 0.0001
I1209 11:25:41.710798 14414 solver.cpp:228] Iteration 240, loss = 3.10645e-06
I1209 11:25:41.710819 14414 solver.cpp:244]     Train net output #0: loss = 3.10424e-06 (* 1 = 3.10424e-06 loss)
I1209 11:25:41.710829 14414 sgd_solver.cpp:106] Iteration 240, lr = 0.0001
I1209 11:25:41.715473 14414 solver.cpp:228] Iteration 252, loss = 1.01293e-06
I1209 11:25:41.715495 14414 solver.cpp:244]     Train net output #0: loss = 1.01072e-06 (* 1 = 1.01072e-06 loss)
I1209 11:25:41.715504 14414 sgd_solver.cpp:106] Iteration 252, lr = 0.0001
I1209 11:25:41.720108 14414 solver.cpp:228] Iteration 264, loss = 4.90261e-06
I1209 11:25:41.720130 14414 solver.cpp:244]     Train net output #0: loss = 4.9004e-06 (* 1 = 4.9004e-06 loss)
I1209 11:25:41.720139 14414 sgd_solver.cpp:106] Iteration 264, lr = 0.0001
I1209 11:25:41.724750 14414 solver.cpp:228] Iteration 276, loss = 2.43915e-06
I1209 11:25:41.724772 14414 solver.cpp:244]     Train net output #0: loss = 2.43694e-06 (* 1 = 2.43694e-06 loss)
I1209 11:25:41.724781 14414 sgd_solver.cpp:106] Iteration 276, lr = 0.0001
I1209 11:25:41.729429 14414 solver.cpp:228] Iteration 288, loss = 4.71797e-07
I1209 11:25:41.729451 14414 solver.cpp:244]     Train net output #0: loss = 4.69587e-07 (* 1 = 4.69587e-07 loss)
I1209 11:25:41.729460 14414 sgd_solver.cpp:106] Iteration 288, lr = 0.0001
I1209 11:25:41.733783 14414 solver.cpp:454] Snapshotting to binary proto file snapshot_iter_300.caffemodel
I1209 11:25:41.734685 14414 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_300.solverstate
I1209 11:25:41.736151 14414 solver.cpp:317] Iteration 300, loss = 5.60014e-07
I1209 11:25:41.736171 14414 solver.cpp:337] Iteration 300, Testing net (#0)
I1209 11:25:41.741295 14414 solver.cpp:404]     Test net output #0: loss = 2.55979e-06 (* 1 = 2.55979e-06 loss)
I1209 11:25:41.741312 14414 solver.cpp:322] Optimization Done.
I1209 11:25:41.741317 14414 caffe.cpp:254] Optimization Done.
